{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anusha_Ayyagari_Data602_Assignment_week7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLYZOzot0R0Z"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_W4unre07E0",
        "outputId": "420c4c64-5b36-4f53-e1d1-9df18b417a6e"
      },
      "source": [
        "#Use the iris data set from sklearn\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "print(iris.DESCR)\n",
        "#print(iris)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OWuDmql1D36",
        "outputId": "c118c507-2a75-48c9-99fd-0fa1dd747986"
      },
      "source": [
        "#Load the iris dataset. What are the features\n",
        "#printing the features of the dataset\n",
        "print(iris.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EtfVmv481Kq5",
        "outputId": "47ce87d3-9183-4bd3-de20-a5bcf7d0fcda"
      },
      "source": [
        "#coverting the features into a dataframe\n",
        "iris_df=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
        "iris_df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
              "0                5.1               3.5                1.4               0.2\n",
              "1                4.9               3.0                1.4               0.2\n",
              "2                4.7               3.2                1.3               0.2\n",
              "3                4.6               3.1                1.5               0.2\n",
              "4                5.0               3.6                1.4               0.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3kZKb0XY43nm",
        "outputId": "39213910-b98d-4abd-c137-2c12f1d7ae64"
      },
      "source": [
        "##coverting the target values into a dataframe\n",
        "target_df=pd.DataFrame(iris.target)\n",
        "target_df.columns=['species']\n",
        "target_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   species\n",
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hui50ISAAVEG",
        "outputId": "bddb2f3b-2acc-44c5-c494-c90a37833dc2"
      },
      "source": [
        "#defining the X and Y paramenters and splitting the data into test and training\n",
        "#Split the dataset into training and test sets (30%)\n",
        "X=iris_df\n",
        "y=target_df\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42)\n",
        "\n",
        "print('the lenghth of the training set is ',len(X_train))\n",
        "print('the lenghth of the test set is ',len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the lenghth of the training set is  105\n",
            "the lenghth of the test set is  45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYOojX0GB-je",
        "outputId": "b8508a08-b0a8-4681-ab9a-7b7188041de9"
      },
      "source": [
        "#Create a Gaussian RandomForestClassifier as clf (2,000 estimators and a depth of 2)\n",
        "#importing the Gaussian RandomForestClassifier  and fitting the training dataset\n",
        "clf=RandomForestClassifier(n_estimators=2000,max_depth=2)\n",
        "clf.fit(X_train,y_train.values.ravel())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=2, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "DrEkqgrJE2We",
        "outputId": "487a3bf6-fc15-45b9-aaeb-68ba167f91e6"
      },
      "source": [
        "#reference https://stackoverflow.com/questions/44101458/random-forest-feature-importance-chart-using-python for getting the feature importances.\n",
        "#-Determine the feature importance. Which one is the most important?(i answered this question post the accuracy measure)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#predicting the results from the classifier\n",
        "predictions=clf.predict(X_test)\n",
        "print('the predictions made by the model for the test datset is ',predictions)\n",
        "\n",
        "#getting the feature importances of the classifiers and converting them into a Series object for easy manipulation\n",
        "feat_importances = pd.Series(clf.feature_importances_, index=iris_df.columns).sort_values(ascending=False)\n",
        "print('the importance of features are ',feat_importances)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "feat_importances.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the predictions made by the model for the test datset is  [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
            " 0 0 0 2 1 1 0 0]\n",
            "the importance of features are  petal length (cm)    0.448087\n",
            "petal width (cm)     0.428048\n",
            "sepal length (cm)    0.107145\n",
            "sepal width (cm)     0.016720\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61e200cc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nxc1pMfoJOK",
        "outputId": "0d79c16d-5660-4a26-e2a8-50f373570f5a"
      },
      "source": [
        "#measuring Accuracy\n",
        "#Use scikitlearn to determine the accuracy level. What is your assessment?\n",
        "from sklearn import metrics\n",
        "accuy_score=metrics.accuracy_score(predictions,y_test)\n",
        "print('the accuracy score is ',accuy_score)\n",
        "\n",
        "from sklearn.metrics import  classification_report\n",
        "forest_class_report=classification_report(y_test,predictions)\n",
        "print(forest_class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the accuracy score is  1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyDq0imcCzOn"
      },
      "source": [
        "What is your assessment?\n",
        "\n",
        "From the above accuracy score we can say the after removing the least importannt features in this case 'sepal width' and 'sepal length' the accuracy of the model is 100%. It also means that our model is highly accurate in predicting the correct class('species' in this case) of the dataset.Also from the feature importances we can see that 'petal length' followed by the 'petal width'  are the most important features for classifying the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuTlyeTwnbn9",
        "outputId": "cc95dd19-bd2e-4caa-fefd-c1a0768b177e"
      },
      "source": [
        "#Use the Gradient Boosting algorithm to fit the model and predict test data\n",
        "#since it has not been  mentioned to  create new datframes and display the features i am directly proceeding to Gradient Boosting algorithm using the dataframes that i have cretaed in the previous sections.\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "#defining the new x any y parameter using the  earlier iris dataframes\n",
        "new_X=iris_df\n",
        "new_y=target_df\n",
        "\n",
        "#print(new_y)\n",
        "\n",
        "#splitting the  data into training and the test  sets\n",
        "newX_train, newX_test, newy_train, newy_test = train_test_split(new_X, new_y, test_size=0.3,random_state=42)\n",
        "\n",
        "print('the lenght of the training set is',len(newX_train))\n",
        "print('the lenght of the test set is',len(newX_test))\n",
        "\n",
        "#using the same parameters as that of random forests for comparision purposes\n",
        "boosting_model=GradientBoostingClassifier(n_estimators=2000,max_depth=2)\n",
        "\n",
        "boosting_model.fit(newX_train,newy_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the lenght of the training set is 105\n",
            "the lenght of the test set is 45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=2,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugGn0qrb8qE2",
        "outputId": "47eee97b-20d9-4764-aeb4-ea78e0a9b5ae"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "new_boost_pred=boosting_model.predict(newX_test)\n",
        "print('the predictions by the model are',new_boost_pred)\n",
        "new_boost_accuracy=metrics.accuracy_score(new_boost_pred,newy_test)\n",
        "print('the accuracy for the model is',new_boost_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the predictions by the model are [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
            " 0 0 0 2 1 1 0 0]\n",
            "the accuracy for the model is 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "ayeWjTU89VSu",
        "outputId": "2a282d29-fd10-4990-b179-ce6cf2074c5c"
      },
      "source": [
        "#getting the feature importances of the classifiers and converting them into a Series object for easy manipulation\n",
        "\n",
        "boosting_feat_importances = pd.Series(boosting_model.feature_importances_, index=iris_df.columns).sort_values(ascending=False)\n",
        "print(boosting_feat_importances)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "boosting_feat_importances.plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "petal length (cm)    0.608653\n",
            "petal width (cm)     0.374756\n",
            "sepal length (cm)    0.009599\n",
            "sepal width (cm)     0.006992\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61e28782d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M4rvmpBU6ic",
        "outputId": "f4eee579-df9a-4951-9360-d67be7292efc"
      },
      "source": [
        "from sklearn.metrics import  classification_report\n",
        "class_report=classification_report(newy_test,new_boost_pred)\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV_PwMzMktpk"
      },
      "source": [
        "Did the Gradient Boosting model perform better? Are there any reservations about GB and why?\n",
        "\n",
        "from the above reports for accuracy and  other parameters the Gradient Boosting Classifier and the Gaussian RandomForestClassifier have similar values so in terms of the performance metrics there both these models are similar but the differnece comes in splitting the features based on the importances. While in the Random Forest eventhough the most important feature is 'petal length' and the second most important feature is 'petal width' the difference is very less and negligible  where as in case of Gradient boosting the diffrenece between these two features is more which makes splitting the features based on important features better than the Random forest.\n",
        "\n",
        "the reservations when it ccomes to gradient boositing is that it is highly susceptible to noise and may result in overfitting. hence we need to tune the parameters for Gradient boosting to avoid this issue. "
      ]
    }
  ]
}